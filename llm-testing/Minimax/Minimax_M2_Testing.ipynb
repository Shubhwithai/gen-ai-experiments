{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header_cell"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Gen AI Experiments](https://img.shields.io/badge/Gen%20AI%20Experiments-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://github.com/buildfastwithai/gen-ai-experiments)\n",
        "[![Gen AI Experiments GitHub](https://img.shields.io/github/stars/buildfastwithai/gen-ai-experiments?style=for-the-badge&logo=github&color=gold)](http://github.com/buildfastwithai/gen-ai-experiments)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1J0xROPPMMShwbxpgvhuOyT5dnwSKPnVP?usp=sharing)\n",
        "\n",
        "## Master Generative AI in 8 Weeks\n",
        "**What You'll Learn:**\n",
        "- Master cutting-edge AI tools & frameworks\n",
        "- 6 weeks of hands-on, project-based learning\n",
        "- Weekly live mentorship sessions\n",
        "- Join Innovation Community\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_cell"
      },
      "source": [
        "# Testing Minimax M2 Free Model Using OpenRouter\n",
        "\n",
        "This notebook provides a comprehensive guide to using the Minimax M2 Free model via OpenRouter's API within the LangChain framework. Minimax M2 is a powerful Chinese AI model that excels in multilingual capabilities, creative writing, and reasoning tasks.\n",
        "\n",
        "**Key Features of Minimax M2:**\n",
        "- Strong multilingual support (especially Chinese and English)\n",
        "- Excellent creative writing capabilities\n",
        "- Good reasoning and analytical skills\n",
        "- Free tier available through OpenRouter\n",
        "\n",
        "**Note:** You will need an API key from [OpenRouter](https://openrouter.ai/) to run the examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "installation_cell"
      },
      "source": [
        "### Installation\n",
        "\n",
        "First, let's install the necessary Python libraries for Minimax M2 testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "%pip install langchain langchain-openai langchain-community tavily-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "basic_usage_header"
      },
      "source": [
        "### Basic Usage with ChatOpenAI and OpenRouter\n",
        "\n",
        "Here's how to set up the `ChatOpenAI` class to connect to the Minimax M2 Free model through OpenRouter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "basic_setup"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# It's recommended to set your API key as an environment variable\n",
        "api_key = userdata.get(\"OPENROUTER_API_KEY\")\n",
        "\n",
        "# Initialize the ChatOpenAI model for Minimax M2 Free\n",
        "minimax_llm = ChatOpenAI(\n",
        "    model=\"minimax/minimax-m2:free\",\n",
        "    openai_api_key=api_key,\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "\n",
        "# Let's test it with a simple prompt\n",
        "response = minimax_llm.invoke(\"What is artificial intelligence and how does it work?\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "multilingual_header"
      },
      "source": [
        "### Multilingual Capabilities\n",
        "\n",
        "Minimax M2 excels in multilingual tasks, especially Chinese and English. Let's test this by sending prompts in different languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "multilingual_test"
      },
      "outputs": [],
      "source": [
        "# Example in Chinese\n",
        "chinese_prompt = \"请解释什么是人工智能，以及它在现代社会中的应用。\"  # Translation: Please explain what AI is and its applications in modern society\n",
        "chinese_response = minimax_llm.invoke(chinese_prompt)\n",
        "print(f\"Response in Chinese:\\n{chinese_response.content}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Example in Spanish\n",
        "spanish_prompt = \"¿Cuáles son las ventajas y desventajas de la inteligencia artificial?\"  # Translation: What are the advantages and disadvantages of AI?\n",
        "spanish_response = minimax_llm.invoke(spanish_prompt)\n",
        "print(f\"Response in Spanish:\\n{spanish_response.content}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Example in Hindi\n",
        "hindi_prompt = \"कृत्रिम बुद्धिमत्ता का भविष्य क्या है?\"  # Translation: What is the future of artificial intelligence?\n",
        "hindi_response = minimax_llm.invoke(hindi_prompt)\n",
        "print(f\"Response in Hindi:\\n{hindi_response.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chatbot_header"
      },
      "source": [
        "### Building a Simple Chatbot\n",
        "\n",
        "We can create a conversational chatbot by managing the chat history. Let's create a creative writing assistant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chatbot_example"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a creative writing assistant that helps users craft engaging stories. You provide vivid descriptions and compelling narratives.\"),\n",
        "    HumanMessage(content=\"I want to write a short story about a time traveler who accidentally changes history. Can you help me start?\"),\n",
        "]\n",
        "\n",
        "# First turn\n",
        "response = minimax_llm.invoke(messages)\n",
        "print(f\"Writing Assistant: {response.content}\")\n",
        "\n",
        "# Add the bot's response to the history\n",
        "messages.append(response)\n",
        "\n",
        "# Second turn\n",
        "messages.append(HumanMessage(content=\"That's great! Now, what if the time traveler realizes they've prevented their own birth? How should the story continue?\"))\n",
        "response = minimax_llm.invoke(messages)\n",
        "print(f\"\\nWriting Assistant: {response.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advanced_header"
      },
      "source": [
        "## Advanced Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tool_calling_header"
      },
      "source": [
        "### Tool Calling and Tavily Search Using Minimax M2\n",
        "\n",
        "Let's create an agent that can use tools, specifically the Tavily search tool for real-time information retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tool_calling_setup"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "import os\n",
        "\n",
        "# 1. Setup LLM via OpenRouter\n",
        "llm = ChatOpenAI(\n",
        "    model=\"minimax/minimax-m2:free\",\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "    openai_api_key=api_key,\n",
        ")\n",
        "\n",
        "# 2. Setup Tavily Search Tool\n",
        "# Note: You'll need a Tavily API key - get one at https://tavily.com/\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")\n",
        "tavily_tool = TavilySearchResults(max_results=2)\n",
        "\n",
        "# 3. Create Agent\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful AI assistant with access to search tools. Provide comprehensive and accurate information.\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "agent = create_tool_calling_agent(llm, [tavily_tool], prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=[tavily_tool], verbose=True)\n",
        "\n",
        "# 4. Run Agent\n",
        "response = agent_executor.invoke({\"input\": \"What are the latest developments in quantum computing in 2024?\"})\n",
        "print(response['output'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_tool_header"
      },
      "source": [
        "### Custom Tool Creation and Agent Workflow\n",
        "\n",
        "Let's create custom tools that showcase Minimax M2's capabilities in mathematical calculations and text analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "custom_tools"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "import math\n",
        "import re\n",
        "\n",
        "@tool\n",
        "def calculate_compound_interest(principal: float, rate: float, time: float, compound_frequency: int = 1) -> str:\n",
        "    \"\"\"Calculate compound interest.\n",
        "\n",
        "    Args:\n",
        "        principal: Initial amount of money\n",
        "        rate: Annual interest rate (as a decimal, e.g., 0.05 for 5%)\n",
        "        time: Time period in years\n",
        "        compound_frequency: Number of times interest is compounded per year (default: 1)\n",
        "    \"\"\"\n",
        "    amount = principal * (1 + rate/compound_frequency)**(compound_frequency * time)\n",
        "    interest = amount - principal\n",
        "    return f\"Principal: ${principal:,.2f}, Final Amount: ${amount:,.2f}, Interest Earned: ${interest:,.2f}\"\n",
        "\n",
        "@tool\n",
        "def analyze_text_sentiment(text: str) -> str:\n",
        "    \"\"\"Analyze the sentiment and characteristics of a given text.\n",
        "\n",
        "    Args:\n",
        "        text: The text to analyze\n",
        "    \"\"\"\n",
        "    word_count = len(text.split())\n",
        "    char_count = len(text)\n",
        "    sentence_count = len(re.split(r'[.!?]+', text.strip()))\n",
        "\n",
        "    # Simple sentiment analysis based on keywords\n",
        "    positive_words = ['good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic', 'love', 'happy']\n",
        "    negative_words = ['bad', 'terrible', 'awful', 'horrible', 'hate', 'sad', 'angry', 'disappointed']\n",
        "\n",
        "    text_lower = text.lower()\n",
        "    positive_count = sum(1 for word in positive_words if word in text_lower)\n",
        "    negative_count = sum(1 for word in negative_words if word in text_lower)\n",
        "\n",
        "    if positive_count > negative_count:\n",
        "        sentiment = \"Positive\"\n",
        "    elif negative_count > positive_count:\n",
        "        sentiment = \"Negative\"\n",
        "    else:\n",
        "        sentiment = \"Neutral\"\n",
        "\n",
        "    return f\"Text Analysis - Words: {word_count}, Characters: {char_count}, Sentences: {sentence_count}, Sentiment: {sentiment}\"\n",
        "\n",
        "# Create agent with multiple tools\n",
        "tools = [tavily_tool, calculate_compound_interest, analyze_text_sentiment]\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "# Test the agent with multiple tool usage\n",
        "response = agent_executor.invoke({\n",
        "    \"input\": \"Calculate the compound interest on $10,000 invested at 5% annual rate for 10 years, compounded quarterly. Then analyze the sentiment of this text: 'I am absolutely thrilled with the amazing results of my investment!'\"\n",
        "})\n",
        "print(response['output'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "parameter_tuning_header"
      },
      "source": [
        "### Advanced Parameter Tuning\n",
        "\n",
        "You can control Minimax M2's output by tuning parameters like `temperature` and `max_tokens`.\n",
        "\n",
        "- **`temperature`**: Controls creativity. Lower values (e.g., 0.1) make output more focused, higher values (e.g., 0.9) more creative.\n",
        "- **`max_tokens`**: Sets the maximum length of the generated response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "parameter_tuning"
      },
      "outputs": [],
      "source": [
        "# Creative response with high temperature\n",
        "creative_llm = ChatOpenAI(\n",
        "    model=\"minimax/minimax-m2:free\",\n",
        "    openai_api_key=api_key,\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "    temperature=0.9,\n",
        "    max_tokens=200\n",
        ")\n",
        "\n",
        "prompt = \"Write a creative short story about a robot who discovers emotions for the first time.\"\n",
        "creative_response = creative_llm.invoke(prompt)\n",
        "print(f\"Creative Story:\\n{creative_response.content}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Factual response with low temperature\n",
        "factual_llm = ChatOpenAI(\n",
        "    model=\"minimax/minimax-m2:free\",\n",
        "    openai_api_key=api_key,\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "prompt = \"Explain the process of photosynthesis in plants, including the chemical equation.\"\n",
        "factual_response = factual_llm.invoke(prompt)\n",
        "print(f\"Factual Explanation:\\n{factual_response.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "code_generation_header"
      },
      "source": [
        "### Code Generation\n",
        "\n",
        "Let's test Minimax M2's code generation capabilities with various programming tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "code_generation"
      },
      "outputs": [],
      "source": [
        "# Python function generation\n",
        "python_prompt = \"Write a Python class for a simple bank account that can deposit, withdraw, and check balance. Include error handling for insufficient funds.\"\n",
        "python_response = minimax_llm.invoke(python_prompt)\n",
        "print(f\"Generated Python Code:\\n{python_response.content}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# JavaScript function generation\n",
        "js_prompt = \"Write a JavaScript function that takes an array of objects with 'name' and 'age' properties and returns the names of people older than 18, sorted alphabetically.\"\n",
        "js_response = minimax_llm.invoke(js_prompt)\n",
        "print(f\"Generated JavaScript Code:\\n{js_response.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "few_shot_header"
      },
      "source": [
        "### Few-Shot Prompting\n",
        "\n",
        "Few-shot prompting helps guide Minimax M2's response format by providing examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "few_shot_example",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3ad420-a8df-4ef4-b254-8b1ddf5fac1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation result: \"我\"爱学习语言。\n",
            "\n",
            "==================================================\n",
            "\n",
            "Pattern completion: **BEE-TREE**\n"
          ]
        }
      ],
      "source": [
        "# Translation task with examples\n",
        "translation_prompt = \"\"\"Translate the following English phrases to Chinese:\n",
        "\n",
        "\"Hello, how are you?\" -> \"你好，你好吗？\"\n",
        "\"Thank you very much\" -> \"非常感谢\"\n",
        "\"What time is it?\" -> \"现在几点了？\"\n",
        "\"I love learning languages\" -> \"\"\"\n",
        "\n",
        "translation_response = minimax_llm.invoke(translation_prompt)\n",
        "print(f\"Translation result: {translation_response.content}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Pattern recognition task\n",
        "pattern_prompt = \"\"\"Complete the pattern:\n",
        "\n",
        "Input: \"The cat sat on the mat\"\n",
        "Output: \"CAT-SAT-MAT\" (extract and capitalize the rhyming words)\n",
        "\n",
        "Input: \"The dog ran in the fog\"\n",
        "Output: \"DOG-FOG\" (extract and capitalize the rhyming words)\n",
        "\n",
        "Input: \"The bee flew to the tree\"\n",
        "Output: \"\"\"\n",
        "\n",
        "pattern_response = minimax_llm.invoke(pattern_prompt)\n",
        "print(f\"Pattern completion: {pattern_response.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "streaming_header"
      },
      "source": [
        "### Streaming Responses\n",
        "\n",
        "For longer responses, you can use streaming to get real-time output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "streaming_example"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Create a streaming version of the model\n",
        "streaming_llm = ChatOpenAI(\n",
        "    model=\"minimax/minimax-m2:free\",\n",
        "    openai_api_key=api_key,\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "    streaming=True\n",
        ")\n",
        "\n",
        "prompt = \"Write a detailed explanation of blockchain technology, covering its key components, how it works, and its real-world applications.\"\n",
        "\n",
        "print(\"Streaming response:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Stream the response\n",
        "for chunk in streaming_llm.stream(prompt):\n",
        "    print(chunk.content, end=\"\", flush=True)\n",
        "    time.sleep(0.01)  # Small delay to visualize streaming\n",
        "\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"✅ Streaming complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "creative_writing_header"
      },
      "source": [
        "### Creative Writing Showcase\n",
        "\n",
        "Minimax M2 excels at creative writing tasks. Let's explore its capabilities in different genres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "creative_writing"
      },
      "outputs": [],
      "source": [
        "# Poetry generation\n",
        "poetry_prompt = \"Write a haiku about the relationship between technology and nature.\"\n",
        "poetry_response = minimax_llm.invoke(poetry_prompt)\n",
        "print(f\"🌸 Haiku:\\n{poetry_response.content}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# Dialogue writing\n",
        "dialogue_prompt = \"Write a dialogue between a young programmer and an experienced AI researcher discussing the future of artificial intelligence. Make it engaging and include different perspectives.\"\n",
        "dialogue_response = minimax_llm.invoke(dialogue_prompt)\n",
        "print(f\"🎭 Dialogue:\\n{dialogue_response.content}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# World-building\n",
        "worldbuilding_prompt = \"Create a brief description of a futuristic city where humans and AI coexist. Include details about the architecture, society, and daily life.\"\n",
        "worldbuilding_response = minimax_llm.invoke(worldbuilding_prompt)\n",
        "print(f\"🏙️ Futuristic City:\\n{worldbuilding_response.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "performance_comparison_header"
      },
      "source": [
        "### Performance Comparison\n",
        "\n",
        "Let's compare Minimax M2 with different temperature settings for various task types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "performance_comparison",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e9828b-2326-44a6-eca5-311ee09d8235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎨 CREATIVE TASK: Writing a poem about AI and creativity\n",
            "============================================================\n",
            "\n",
            "🌡️ Testing with temperature: 0.1\n",
            "----------------------------------------\n",
            "Response: \n",
            "⏱️ Time taken: 3.67 seconds\n",
            "\n",
            "🌡️ Testing with temperature: 0.5\n",
            "----------------------------------------\n",
            "Response: \n",
            "⏱️ Time taken: 2.84 seconds\n",
            "\n",
            "🌡️ Testing with temperature: 0.9\n",
            "----------------------------------------\n",
            "Response: \n",
            "⏱️ Time taken: 3.85 seconds\n",
            "\n",
            "\n",
            "📊 ANALYTICAL TASK: Explaining a technical concept\n",
            "============================================================\n",
            "\n",
            "🌡️ Testing with temperature: 0.1\n",
            "----------------------------------------\n",
            "Response: Think of a neural network like a very simple model of how your brain works, but much smaller and dumber than your actual brain!\n",
            "\n",
            "## The Basic Idea\n",
            "\n",
            "Imagine you're trying to identify what's in a photo. Your brain doesn't look at every single pixel at once - different parts of your brain specialize in different things. Some cells detect edges, others recognize shapes\n",
            "⏱️ Time taken: 3.27 seconds\n",
            "\n",
            "🌡️ Testing with temperature: 0.5\n",
            "----------------------------------------\n",
            "Response: \n",
            "⏱️ Time taken: 6.65 seconds\n",
            "\n",
            "🌡️ Testing with temperature: 0.9\n",
            "----------------------------------------\n",
            "Response: # Neural Networks Explained Simply\n",
            "\n",
            "Think of a neural network like a very talented student that's really good at recognizing patterns.\n",
            "\n",
            "## The Basic Idea\n",
            "\n",
            "**What it is**: A neural network is a computer system designed to learn from examples, much like how you might learn to recognize different dog breeds by seeing many pictures.\n",
            "\n",
            "**The name comes from**: It was inspired by how\n",
            "⏱️ Time taken: 3.34 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def test_model_performance(prompt, temperatures=[0.1, 0.5, 0.9]):\n",
        "    \"\"\"Test the same prompt with different temperature settings\"\"\"\n",
        "    results = {}\n",
        "\n",
        "    for temp in temperatures:\n",
        "        print(f\"\\n🌡️ Testing with temperature: {temp}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        test_llm = ChatOpenAI(\n",
        "            model=\"minimax/minimax-m2:free\",\n",
        "            openai_api_key=api_key,\n",
        "            openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "            temperature=temp,\n",
        "            max_tokens=150\n",
        "        )\n",
        "\n",
        "        start_time = time.time()\n",
        "        response = test_llm.invoke(prompt)\n",
        "        end_time = time.time()\n",
        "\n",
        "        results[temp] = {\n",
        "            'response': response.content,\n",
        "            'time': end_time - start_time\n",
        "        }\n",
        "\n",
        "        print(f\"Response: {response.content}\")\n",
        "        print(f\"⏱️ Time taken: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Test with a creative prompt\n",
        "creative_prompt = \"Write a short poem about artificial intelligence and human creativity.\"\n",
        "print(\"🎨 CREATIVE TASK: Writing a poem about AI and creativity\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "creative_results = test_model_performance(creative_prompt)\n",
        "\n",
        "print(\"\\n\\n📊 ANALYTICAL TASK: Explaining a technical concept\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test with an analytical prompt\n",
        "analytical_prompt = \"Explain the concept of neural networks in simple terms.\"\n",
        "analytical_results = test_model_performance(analytical_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary_cell"
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated the capabilities of Minimax M2 Free model through OpenRouter, including:\n",
        "\n",
        "### ✅ **Core Features Tested:**\n",
        "1. **Basic Setup**: Configuration and initialization with OpenRouter\n",
        "2. **Multilingual Support**: Excellent performance in Chinese, English, Spanish, and Hindi\n",
        "3. **Creative Writing**: Strong capabilities in poetry, dialogue, and storytelling\n",
        "4. **Agent Workflows**: Tool calling and integration with external services\n",
        "5. **Custom Tools**: Mathematical calculations and text analysis\n",
        "6. **Code Generation**: Python and JavaScript programming assistance\n",
        "7. **Parameter Tuning**: Temperature control for creativity vs. precision\n",
        "8. **Few-Shot Learning**: Pattern recognition and guided responses\n",
        "9. **Streaming**: Real-time response generation\n",
        "10. **Performance Testing**: Comparison across different configurations\n",
        "\n",
        "### 🌟 **Key Strengths of Minimax M2:**\n",
        "- **Multilingual Excellence**: Particularly strong in Chinese-English tasks\n",
        "- **Creative Writing**: Outstanding performance in creative and narrative tasks\n",
        "- **Cultural Understanding**: Good grasp of cultural nuances in different languages\n",
        "- **Free Tier**: Accessible through OpenRouter's free tier\n",
        "- **Versatility**: Handles both analytical and creative tasks effectively\n",
        "\n",
        "### 💡 **Best Use Cases:**\n",
        "- Multilingual content creation and translation\n",
        "- Creative writing and storytelling\n",
        "- Educational content development\n",
        "- Cross-cultural communication tools\n",
        "- Prototype development for AI applications\n",
        "\n",
        "Minimax M2 Free offers excellent value for developers and researchers looking to experiment with a capable multilingual AI model without cost barriers. Its strong performance in creative tasks and multilingual scenarios makes it particularly valuable for international applications and creative projects."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}